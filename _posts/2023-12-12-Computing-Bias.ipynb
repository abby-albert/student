{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "toc: true\n",
    "comments: true\n",
    "layout: post\n",
    "title: Computing Bias\n",
    "description: College Board Big Idea 5.3 Computing Bias Student Lesson\n",
    "type: hacks\n",
    "courses: { compsci: {week: 15} }\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Biases Reflected As Computer Biases\n",
    "\n",
    "**Bias**: prejudice in favor of or against a thing, person, or group\n",
    "\n",
    "## What is \"computer bias\"?\n",
    "The existence of prejudiced outcomes in the decisions or predictions made by computer systems/algorithms. Bias can be implemented into algorithms because of human biases being intentionally inserted or because of the data utilized being biased.\n",
    "\n",
    "**Explicit Data:**\n",
    "Information directly provided by user.\n",
    "\n",
    "**Implicit Data:**\n",
    "Infomration that can inferred from explicit data. \n",
    "\n",
    "Based on either explicit/implicit data that has been used to train an algorithm, whether intentionally introduced or during the process of training data generation, bias can be created.\n",
    "\n",
    "<img src=\"https://static01.nyt.com/images/2020/03/10/multimedia/ihw-nudgebias/ihw-nudgebias-mediumSquareAt3X.jpg\" width=\"450\" length=\"450\">\n",
    "\n",
    "A notable example of this is seen in Netflix, where there are is a human factor that drives bias: Netflix exclusives are placed ahead (a show that is a Netflix exclusive means that users will be more likely to stay with Netflix). The bias in this case is Netflix's prioritzation towards Netflix-produced shows.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*8BtlgpxyjOPaLZXO6pVD0Q.jpeg\" width=\"700\" length=\"394\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 1: \n",
    "What is another example of a human bias being implemented into an algorithm? \n",
    "> Answer: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Bias\n",
    "Programmers should take action to reduce bias in algorithms used for computing innovations as a way of combating existing human biases. Softwares need to be unbiased, consider all everything, and reject human bias.\n",
    "\n",
    "Things to consider when developing programs:\n",
    "- What are potential sources of bias?\n",
    "- Is your program enhancing or intentionally excluding?\n",
    "- Are you receiving feedback from a widespread group of people?\n",
    "- How could people who differ from you use your developments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 2: \n",
    "What is another way a programmer can reduce bias in their softwares?\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Bias in Software Development\n",
    "Biases can be embedded at all levels of software development.\n",
    "\n",
    "It can be intentional or unintentional. Some software development are made for a certain market and ensure that people of certain places or demographics can use them easily. However, this doesn't mean that they are trying to exclude.  \n",
    "\n",
    "Examples: \n",
    "\n",
    "**Intentional**: \n",
    "- Games could be geared towards a certain age range (Talking Tom vs Valorant)\n",
    "    - Game concepts\n",
    "    - Music\n",
    "    - Visuals\n",
    "\n",
    "<img src=\"https://is1-ssl.mzstatic.com/image/thumb/PurpleSource126/v4/fb/63/3e/fb633e5e-920b-aab4-3b5e-770edca48ca8/011eb6d7-683f-4586-8794-fa67e2dfc403_screenshot_ipad_en-US_6577036012549030604.jpg/643x0w.jpg\" width=\"429\" length=\"572\">\n",
    "<img src=\"https://www.pcgameshardware.de/screenshots/1280x/2020/03/Reveal_Window_VALORANT-pcgh.jpg\" width=\"640\" length=\"360\">\n",
    "\n",
    "- WeChat and KakaoTalk\n",
    "    - Almost everyone in China uses WeChat\n",
    "    - KakaoTalk is the Korean version\n",
    "\n",
    "**Unintentional**: \n",
    "- Social media, Facebook vs. instagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hack 3:\n",
    "What are some other examples of intentional and/or unintentional bias in innovations (games, social media, technology, etc.)?\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "### Question 1: \n",
    "Define \"computer bias\" in your own words and explain how it can result from intentional or unintentional factors in software development. Give a brief example of this. Explain how programmers can actively work to reduce bias in their algorithms?\n",
    "\n",
    "> Answer: \"Computer bias\" refers to the presence of systematic and unfair discrepancies in the outcomes, decisions, or predictions made by computer systems or algorithms, often reflecting existing biases in the data used for training or the design choices made during software development. This bias can stem from intentional or unintentional factors, influencing how algorithms treat different individuals or groups. The two factors that lead to computer bias are intentional factors and unintentional factors. To reduce bias in algorithems you can use diverse and representative data, bias audits, and explainable AI (XAI).\n",
    "\n",
    "### Question 2:\n",
    "Briefly describe the two types of bias in software development and provide examples from the gaming industry and social media platforms. How might biases in software design affect user engagement and experiences?\n",
    "\n",
    "> Answer: There are two main types of bias in software development: algorithmic bias and representation bias. Two examples of bias are gaming industries and social-media platforms. Gaming industries as algorithmic because if a game's AI is trained on data that predominantly features aggressive behavior from a specific demographic, it may result in biased character behaviors in the game. Gaming industries as representatiob because if the development team lacks diversity, there may be a tendency to create characters that reflect the cultural or gender norms of the developers, leading to a lack of representation for various groups. Social Media platforms as algorithmic becaused if a social media algorithm predominantly shows users content aligned with their existing beliefs, it may reinforce filter bubbles and limit exposure to diverse perspectives. Social media platforms because if the design team lacks diversity, emoji sets may unintentionally reflect the perspectives of a particular group, potentially overlooking the needs and expressions of other communities. Biases in software design can effect user engagement and experiences by the reinforcement of stereotypes, limited diversity of perspectives, user alienation, and filter bubbles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
